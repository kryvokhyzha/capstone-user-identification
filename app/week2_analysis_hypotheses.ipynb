{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://habrastorage.org/web/677/8e1/337/6778e1337c3d4b159d7e99df94227cb2.jpg\"/>\n",
    "## Специализация \"Машинное обучение и анализ данных\"\n",
    "</center>\n",
    "<center>Автор материала: программист-исследователь Mail.ru Group, старший преподаватель Факультета Компьютерных Наук ВШЭ Юрий Кашницкий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Capstone проект №1. Идентификация пользователей по посещенным веб-страницам\n",
    "<img src='http://i.istockimg.com/file_thumbview_approve/21546327/5/stock-illustration-21546327-identification-de-l-utilisateur.jpg'>\n",
    "\n",
    "# <center>Неделя 2. Подготовка и первичный анализ данных\n",
    "\n",
    "На второй неделе мы продолжим подготавливать данные для дальнейшего анализа и построения прогнозных моделей. Конкретно, раньше мы определили что сессия – это последовательность из 10 посещенных пользователем сайтов, теперь сделаем длину сессии параметром, и потом при обучении прогнозных моделей выберем лучшую длину сессии.\n",
    "Также мы познакомимся с предобработанными данными и статистически проверим первые гипотезы, связанные с нашими наблюдениями. \n",
    "\n",
    "**План 2 недели:**\n",
    " - Часть 1. Подготовка нескольких обучающих выборок для сравнения\n",
    " - Часть 2. Первичный анализ данных, проверка гипотез\n",
    "\n",
    "**В этой части проекта Вам могут быть полезны  следующие видеозаписи лекций курса \"Построение выводов по данным\":**\n",
    "\n",
    "   - [Доверительные интервалы для доли](https://www.coursera.org/learn/stats-for-data-analysis/lecture/3oi53/dovieritiel-nyie-intiervaly-dlia-doli)\n",
    "   - [Биномиальный критерий для доли](https://www.coursera.org/learn/stats-for-data-analysis/lecture/JwmBw/binomial-nyi-kritierii-dlia-doli)\n",
    "   - [Доверительные интервалы на основе бутстрепа](https://www.coursera.org/learn/stats-for-data-analysis/lecture/GZjW7/dovieritiel-nyie-intiervaly-na-osnovie-butstriepa)\n",
    "   \n",
    "**Кроме того, в задании будут использоваться библиотеки Python [glob](https://docs.python.org/3/library/glob.html), [pickle](https://docs.python.org/2/library/pickle.html), [itertools](https://docs.python.org/3/library/itertools.html) и класс [csr_matrix](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.sparse.csr_matrix.html) из scipy.sparse.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Подготовка нескольких обучающих выборок для сравнения\n",
    "\n",
    "Пока мы брали последовательности из 10 сайтов, и это было наобум. Давайте сделаем число сайтов в сессии параметром, чтоб в дальнейшем сравнить модели классификации, обученные на разных выборках – с 5, 7, 10 и 15 сайтами в сессии. Более того, пока мы брали по 10 сайтов подряд, без пересечения. Теперь давайте применим идею скользящего окна – сессии будут перекрываться. \n",
    "\n",
    "**Пример**: для длины сессии 10 и ширины окна 7 файл из 30 записей породит не 3 сессии, как раньше (1-10, 11-20, 21-30), а 5 (1-10, 8-17, 15-24, 22-30, 29-30). При этом в предпоследней сессии будет один ноль, а в последней – 8 нолей.\n",
    "\n",
    "Создадим несколько выборок для разных сочетаний параметров длины сессии и ширины окна. Все они представлены в табличке ниже:\n",
    "\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-031e\">session_length -&gt;<br>window_size <br></th>\n",
    "    <th class=\"tg-031e\">5</th>\n",
    "    <th class=\"tg-031e\">7</th>\n",
    "    <th class=\"tg-031e\">10</th>\n",
    "    <th class=\"tg-031e\">15</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-031e\">5</td>\n",
    "    <td class=\"tg-031e\">v</td>\n",
    "    <td class=\"tg-031e\">v</td>\n",
    "    <td class=\"tg-031e\">v</td>\n",
    "    <td class=\"tg-031e\">v</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-031e\">7</td>\n",
    "    <td class=\"tg-031e\"></td>\n",
    "    <td class=\"tg-031e\">v</td>\n",
    "    <td class=\"tg-031e\">v</td>\n",
    "    <td class=\"tg-031e\">v</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-031e\">10</td>\n",
    "    <td class=\"tg-031e\"></td>\n",
    "    <td class=\"tg-031e\"></td>\n",
    "    <td class=\"tg-031e\"><font color='green'>v</font></td>\n",
    "    <td class=\"tg-031e\">v</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "Итого должно получиться 18 разреженных матриц – указанные в таблице 9 сочетаний параметров формирования сессий для выборок из 10 и 150 пользователей. При этом 2 выборки мы уже сделали в прошлой части, они соответствуют сочетанию параметров: session_length=10, window_size=10, которые помечены в таблице выше галочкой зеленого цвета (done)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте функцию *prepare_sparse_train_set_window*.\n",
    "\n",
    "Аргументы:\n",
    "- *path_to_csv_files* – путь к каталогу с csv-файлами\n",
    "- *site_freq_path* – путь к pickle-файлу с частотным словарем, полученным в 1 части проекта\n",
    "- *session_length* – длина сессии (параметр)\n",
    "- *window_size* – ширина окна (параметр) \n",
    "\n",
    "Функция должна возвращать 2 объекта:\n",
    "- разреженную матрицу *X_sparse* (двухмерная Scipy.sparse.csr_matrix), в которой строки соответствуют сессиям из *session_length* сайтов, а *max(site_id)* столбцов – количеству посещений *site_id* в сессии. \n",
    "- вектор *y* (Numpy array) \"ответов\" в виде ID пользователей, которым принадлежат сессии из *X_sparse*\n",
    "\n",
    "Детали:\n",
    "- Модифицируйте созданную в 1 части функцию *prepare_train_set*\n",
    "- Некоторые сессии могут повторяться – оставьте как есть, не удаляйте дубликаты\n",
    "- Замеряйте время выполнения итераций цикла с помощью *time* из *time*, *tqdm* из *tqdm* или с помощью виджета [log_progress](https://github.com/alexanderkuk/log-progress) ([статья](https://habrahabr.ru/post/276725/) о нем на Хабрахабре)\n",
    "- 150 файлов из *capstone_websites_data/150users/* должны обрабатываться за несколько секунд (в зависимости от входных параметров). Если дольше – не страшно, но знайте, что функцию можно ускорить. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "# отключим всякие предупреждения Anaconda\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from glob import glob\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy import stats\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поменяйте на свой путь к данным\n",
    "PATH_TO_DATA = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_set_window(path_to_csv_files, site_freq_path, session_length, window_size):\n",
    "#     train_set = {}\n",
    "    train_set = pd.DataFrame()\n",
    "    last_site_id = 1\n",
    "    with open(site_freq_path, 'rb') as handle:\n",
    "        vocabulary = pickle.load(handle)\n",
    "        \n",
    "    for file in os.listdir(path_to_csv_files):\n",
    "        if not file.endswith('.csv'):\n",
    "            continue\n",
    "    \n",
    "#         print(f'File: {file}')\n",
    "        \n",
    "        df = pd.read_csv(os.path.join(path_to_csv_files, file))\n",
    "        \n",
    "        user_id = int(file[4:-4])\n",
    "        \n",
    "        delta = 0 if df.shape[0] % window_size == 0 else 1\n",
    "        steps_cnt = df.shape[0] // window_size\n",
    "        steps_cnt += delta\n",
    "        \n",
    "        rows_seq = []\n",
    "        \n",
    "        for i in range(steps_cnt):\n",
    "            df_temp = df[i*window_size:(i+1)*window_size].values\n",
    "            sites_seq = [vocabulary[x[1]][0] for x in df_temp]\n",
    "#             print(sites_seq)\n",
    "            sites_seq = sites_seq + [0] * (session_length - len(sites_seq))\n",
    "            t = {f'site{key+1}': val for (key, val) in enumerate(sites_seq)}\n",
    "            t['user_id'] = user_id\n",
    "            rows_seq.append(t)\n",
    "            sites_seq = []\n",
    "                    \n",
    "        train_set = train_set.append(rows_seq, ignore_index=True)\n",
    "    return train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sparse_data(data):\n",
    "    indptr = [0]\n",
    "    indices = []\n",
    "    sparse_data = []\n",
    "    for row in data:\n",
    "        val, cnt = np.unique(row[row != 0], return_counts=True)\n",
    "        indptr.append(indptr[-1] + len(val))\n",
    "        for v, c in zip(val, cnt):\n",
    "            indices.append(v - 1)\n",
    "            sparse_data.append(c)\n",
    "    return np.uint64(sparse_data),  np.uint64(indices), np.uint64(indptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sparse_train_set_window(path_to_csv_files, site_freq_path, \n",
    "                                    session_length=10, window_size=10):\n",
    "    train_set = prepare_train_set_window(path_to_csv_files, site_freq_path, session_length, window_size)\n",
    "    X, y = train_set.iloc[:, :-1].values, train_set.iloc[:, -1].values\n",
    "    return csr_matrix(make_sparse_data(X)), y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примените полученную функцию с параметрами *session_length=5* и *window_size=3* к игрушечному примеру. Убедитесь, что все работает как надо.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.5 ms, sys: 10 ms, total: 20.5 ms\n",
      "Wall time: 19.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_toy_s5_w3, y_s5_w3 = prepare_sparse_train_set_window(os.path.join(PATH_TO_DATA,'3users'), \n",
    "                                                       os.path.join(PATH_TO_DATA,'site_freq_3users.pkl'),\n",
    "                                       session_length=10, window_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 2, 0, 1, 4, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 2, 1, 0, 1, 0, 0, 0, 0],\n",
       "        [1, 3, 0, 0, 1, 1, 0, 1, 1, 0, 0],\n",
       "        [1, 0, 0, 0, 3, 0, 0, 0, 0, 1, 1]], dtype=uint64)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_toy_s5_w3.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 3, 1, 1])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_s5_w3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Запустите созданную функцию 16 раз с помощью циклов по числу пользователей num_users (10 или 150), значениям параметра *session_length* (15, 10, 7 или 5) и значениям параметра *window_size* (10, 7 или 5). Сериализуйте все 16 разреженных матриц (обучающие выборки) и векторов (метки целевого класса – ID пользователя) в файлы `X_sparse_{num_users}users_s{session_length}_w{window_size}.pkl` и `y_{num_users}users_s{session_length}_w{window_size}.pkl`.**\n",
    "\n",
    "**Чтоб убедиться, что мы все далее будем работать с идентичными объектами, запишите в список *data_lengths* число строк во всех полученных рареженных матрицах (16 значений). Если какие-то будут совпадать, это нормально (можно сообразить, почему).**\n",
    "\n",
    "**На моем ноутбуке этот участок кода отработал за 26 секунд, хотя понятно, что все зависит от эффективности реализации функции *prepare_sparse_train_set_window* и мощности используемого железа. И честно говоря, моя первая реализация была намного менее эффективной (34 минуты), так что тут у Вас есть возможность оптимизировать свой код.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 49s, sys: 816 ms, total: 2min 50s\n",
      "Wall time: 2min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import itertools\n",
    "\n",
    "data_lengths = []\n",
    "\n",
    "for num_users in [10, 150]:\n",
    "    for window_size, session_length in itertools.product([10, 7, 5], [15, 10, 7, 5]):\n",
    "        if window_size <= session_length and (window_size, session_length) != (10, 10):\n",
    "            X_sparse, y = prepare_sparse_train_set_window(os.path.join(PATH_TO_DATA,f'{num_users}users'), \n",
    "                                                          os.path.join(PATH_TO_DATA,f'site_freq_{num_users}users.pkl'),\n",
    "                                                          session_length=session_length, window_size=window_size)\n",
    "            with open(os.path.join(PATH_TO_DATA, f'X_sparse_{num_users}users_s{session_length}_w{window_size}.pkl'), 'wb') as X_pkl:\n",
    "                pickle.dump(X_sparse, X_pkl, protocol=2)\n",
    "            with open(os.path.join(PATH_TO_DATA, f'y_{num_users}users_s{session_length}_w{window_size}.pkl'), 'wb') as y_pkl:\n",
    "                pickle.dump(y, y_pkl, protocol=2)\n",
    "                \n",
    "            data_lengths.append(X_sparse.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Запишите в файл *answer2_1.txt* все числа из списка *data_lengths* через пробел. Полученный файл будет ответом на 1 вопрос теста.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_answer_to_file(answer, file_address):\n",
    "    with open(file_address, 'w') as out_f:\n",
    "        out_f.write(str(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_answer_to_file(' '.join(map(str, data_lengths)), \n",
    "                     'answer2_1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Первичный анализ данных, проверка гипотез"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Считаем в DataFrame подготовленный на 1 неделе файл `train_data_10users.csv`. Далее будем работать с ним.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_data_10users.csv'), \n",
    "                       index_col='session_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>site2</th>\n",
       "      <th>site3</th>\n",
       "      <th>site4</th>\n",
       "      <th>site5</th>\n",
       "      <th>site6</th>\n",
       "      <th>site7</th>\n",
       "      <th>site8</th>\n",
       "      <th>site9</th>\n",
       "      <th>site10</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1  site2  site3  site4  site5  site6  site7  site8  site9  \\\n",
       "session_id                                                                  \n",
       "0               1      2      2      3      4      4      4      5      5   \n",
       "1               7      8      7      4      9     10     11     12      9   \n",
       "2              14     15     15      9     15      9      9      4      4   \n",
       "3              12     15     15     16     17     13     18     19     20   \n",
       "4              22     23     19     21     24     19     25     26     21   \n",
       "\n",
       "            site10  user_id  \n",
       "session_id                   \n",
       "0                6       39  \n",
       "1               13       39  \n",
       "2                9       39  \n",
       "3               21       39  \n",
       "4               19       39  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14061 entries, 0 to 14060\n",
      "Data columns (total 11 columns):\n",
      " #   Column   Non-Null Count  Dtype\n",
      "---  ------   --------------  -----\n",
      " 0   site1    14061 non-null  int64\n",
      " 1   site2    14061 non-null  int64\n",
      " 2   site3    14061 non-null  int64\n",
      " 3   site4    14061 non-null  int64\n",
      " 4   site5    14061 non-null  int64\n",
      " 5   site6    14061 non-null  int64\n",
      " 6   site7    14061 non-null  int64\n",
      " 7   site8    14061 non-null  int64\n",
      " 8   site9    14061 non-null  int64\n",
      " 9   site10   14061 non-null  int64\n",
      " 10  user_id  14061 non-null  int64\n",
      "dtypes: int64(11)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Распределение целевого класса:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128    2796\n",
       "39     2204\n",
       "207    1868\n",
       "127    1712\n",
       "237    1643\n",
       "33     1022\n",
       "50      802\n",
       "31      760\n",
       "100     720\n",
       "241     534\n",
       "Name: user_id, dtype: int64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['user_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посчитаем распределение числа уникальных сайтов в каждой сессии из 10 посещенных подряд сайтов.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_unique_sites = [np.unique(train_df.values[i, :-1]).shape[0] \n",
    "                    for i in range(train_df.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7     2308\n",
       "6     2197\n",
       "8     2046\n",
       "5     1735\n",
       "9     1394\n",
       "2     1246\n",
       "4     1163\n",
       "3      894\n",
       "10     651\n",
       "1      427\n",
       "dtype: int64"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(num_unique_sites).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(num_unique_sites).hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проверьте с помощью QQ-плота и критерия Шапиро-Уилка, что эта величина распределена нормально. Сделайте вывод. Ответом на второй вопрос в тесте будет файл со словом \"YES\" или \"NO\" в зависимости от того, распределено ли нормально число уникальных сайтов в сессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "''' ВАШ КОД ЗДЕСЬ '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "''' ВАШ КОД ЗДЕСЬ '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "write_answer_to_file(''' ВАШ КОД ЗДЕСЬ ''', \n",
    "                     'answer2_2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проверьте гипотезу о том, что пользователь хотя бы раз зайдет на сайт, который он уже ранее посетил в сессии из 10 сайтов. Давайте проверим с помощью биномиального критерия для доли, что доля случаев, когда пользователь повторно посетил какой-то сайт (то есть число уникальных сайтов в сессии < 10) велика: больше 95% (обратите внимание, что альтернатива тому, что доля равна 95% –  одностороняя). Ответом на 3 вопрос в тесте будет полученное p-value.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "has_two_similar = (np.array(num_unique_sites) < 10).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pi_val = stats.binom_test  ''' ВАШ КОД ЗДЕСЬ '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "write_answer_to_file(''' ВАШ КОД ЗДЕСЬ ''', \n",
    "                     'answer2_3.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Постройте для этой доли 95% доверительный интервал Уилсона. Округлите границы интервала до 3 знаков после запятой и запишите через пробел в файл *answer2_4.txt*. Это будет ответом на 4 вопрос теста.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "wilson_interval = ''' ВАШ КОД ЗДЕСЬ '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "write_answer_to_file('{} {}'.format(round(wilson_interval[0], 3),\n",
    "                                   round(wilson_interval[1], 3)), \n",
    "                     'answer2_4.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Постройте распределение частоты посещения сайтов (сколько раз тот или иной сайт попадается в выборке) для сайтов, которые были посещены как минимум 1000 раз.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "site_freqs = ''' ВАШ КОД ЗДЕСЬ '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "''' ВАШ КОД ЗДЕСЬ '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Постройте 95% доверительный интервал для средней частоты появления сайта в выборке (во всей, уже не только для тех сайтов, что были посещены как минимум 1000 раз) на основе bootstrap. Используйте столько же bootstrap-подвыборок, сколько сайтов оказалось в исходной выборке по 10 пользователям. Берите подвыборки из посчитанного списка частот посещений сайтов – не надо заново считать эти частоты. Учтите, что частоту появления нуля (сайт с индексом 0 появлялся там, где сессии были короче 10 сайтов) включать не надо. Округлите границы интервала до 3 знаков после запятой и запишите через пробел в файл *answer2_5.txt*. Это будет ответом на 5 вопрос теста.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_bootstrap_samples(data, n_samples, random_seed=17):\n",
    "    np.random.seed(random_seed)\n",
    "    indices = np.random.randint(0, len(data), (n_samples, len(data)))\n",
    "    samples = data[indices]\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def stat_intervals(stat, alpha):\n",
    "    boundaries = np.percentile(stat, \n",
    "                 [100 * alpha / 2., 100 * (1 - alpha / 2.)])\n",
    "    return boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "''' ВАШ КОД ЗДЕСЬ '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "write_answer_to_file('{} {}'.format(''' ВАШ КОД ЗДЕСЬ ''', \n",
    "                                    'answer2_5.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пути улучшения\n",
    "В этом проекте свобода творчества на каждом шаге, а 7 неделя проекта посвящена общему описанию (`html`, `ipynb` или `pdf`) и взаимному оцениванию проектов. Что еще можно добавить по второй части проекта:\n",
    "- можно дополнительно рассматривать сессии с параметром – длиной сессии по времени. И составить выборки, скажем, для 5-, 10-, 15- и 20-минутных сессий (это как раз пригодится в [соревновании](https://inclass.kaggle.com/c/identify-me-if-you-can4) Kaggle Inclass)\n",
    "- можно провести больше первичного анализа и проверять прочие интересные гипотезы (а больше их появится после создания признаков на следующей неделе)\n",
    "\n",
    "На 3 неделе мы займемся визуальным анализом данных и построением признаков."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
